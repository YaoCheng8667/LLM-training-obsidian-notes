### ðŸ”–Main Menu & Checklist[^1]
+ **Transformer and SOTA Models**
	- [ ] Transformer 
	- [ ] Large Language Models
	- [ ] Multi-Modal models
+ **LLM training stages**
	- [ ] Data preprocess
	- [ ] Pretrain
	- [ ] SFT
	- [ ] RLHF
	- [ ] Inference & Deployment
+ **Training Framework**
	- [ ] [[torch]]
	- [ ] Hugging-Face
	- [ ] megatron-LM
	- [ ] deepspeed
+ **Parallelize & acceleration for training**
	- [ ] Profiling
	- [ ] Cuda / ROCm kernel Acceleration
	- [ ] Parallelism
+ **Cluster Management**
	- [ ] Network NVLink & RDMA
	- [ ] Slurm
	- [ ] Kubernetes
+ **Model evaluation**

[^1]: *mainly reference* https://llmbook-zh.github.io/LLMBook.pdf
